{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TTtW67-nMw8vN5uBvqLs4MmY3DwZ859Q","timestamp":1620303182851},{"file_id":"1_TS09TEkdKWVIKj4YWSkU0f3HhPE3SzZ","timestamp":1620123384495},{"file_id":"1D9rRLYyzXp-CQrCJZ2Bt7PQK2le0BZqK","timestamp":1619884931092}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OXeFdzJxmyfF"},"source":["# Neural Actor Critic\n","\n","**Applications of Deep Learning, University of Zaragoza, Ruben Martinez-Cantin**\n","\n","*This assigment is based on the UC Berkeley course CS 285: Deep Reinforcement Learning by Sergei Levine.*\n","\n","This assignment requires you to implement an actor critic algorithm to solve certain tasks. This assigment is very similar to the project (where you will implement a DQN algorithm), but it is relatively shorter. The actual coding for this assignment will involve less than 20 lines\n","of code.\n","\n","Recall the policy gradient equation:\n","$$\n","  \\nabla_\\theta J (\\theta) = \\frac{1}{N} \\sum_{i=1}^N \\sum_{t=1}^{T} \\log \\nabla_\\theta \\pi_\\theta(a_{i,t} | s_{i,t}) A^\\pi(s_{i,t}, a_{i,t})\n","$$\n","Using the sum of the rewards to go like in policy gradient methods, the estimated advantage value $A^\\pi$ suffers from high variance. Actor-critic addresses this issue by using a critic network to estimate the sum of rewards to go.\n","\n","The most common type of critic network used is a value function, in which case our estimated advantage becomes\n","$$\n","A^\\pi(s_{t}, a_{t}) = r(s_{t}, a_{t}) + \\gamma V_\\phi^\\pi(s_{t+1}) - V_\\phi^\\pi(s_{t})\n","$$\n","One additional consideration in actor-critic is updating the critic network itself. While we can use Monte Carlo rollouts to estimate the sum of rewards to go for updating the value function network, in practice we\n","fit our value function to the following *target values*:\n","$$\n","y_t = r(s_{t}, a_{t}) + \\gamma V^\\pi(s_{t+1})\n","$$\n","we then regress onto these target values via the following regression objective which we can optimize with gradient descent:\n","$$\n","\\min_\\phi \\sum_{i,t}(V_\\phi^\\pi(s_{t}) - y_t)^2\n","$$\n","In theory, we need to perform this minimization every time we update our policy, so that our value function\n","matches the behavior of the new policy. In practice however, this operation can be costly, so we may instead\n","just take a few gradient steps at each iteration. Also note that since our target values are based on the\n","old value function, we may need to recompute the targets with the updated value function, in the following\n","fashion:\n","1. Update targets with current value function\n","2. Regress onto targets to update value function by taking a few gradient steps\n","3. Redo steps 1 and 2 several times\n","In all, the process of fitting the value function critic is an iterative process in which we go back and forth\n","between computing target values and updating the value function to match the target values. Through\n","experimentation, you will see that this iterative process is crucial for training the critic network.\n","\n","# 1. Implementation\n","\n","You will need to fill in the TODOS for the following parts of the code.\n","* In Policy and Critic section you should implement the update methods for both networks. In the Critic perform the update according to process outlined in the introduction. You must perform\n","`self.num_target_updates * self.num_grad_steps_per_target_update`\n","number of updates, and recompute the target values every `self.num_grad_steps_per_target_update` number of steps.\n","* In Agent section, finish the estimate_advantage function: this function uses the critic network to estimate the advantage values. The advantage values are computed according to\n","$$\n","A^\\pi(s_{t}, a_{t}) = r(s_{t}, a_{t}) + \\gamma V_\\phi^\\pi(s_{t+1}) - V_\\phi^\\pi(s_{t})\n","$$\n","Note: for terminal timesteps, you must make sure to cut of the reward to go (i.e., set it to zero), in which case we have\n","$$\n","A^\\pi(s_{t}, a_{t}) = r(s_{t}, a_{t}) - V_\\phi^\\pi(s_{t})\n","$$\n","\n","# 2. Evaluation\n","Now that you have implemented actor-critic, check that your solution works by running `CartPole-v0`. This experiment should run quite fast compared with the other experiments, so you can use it to debugging.\n","\n","To test the CartPole, you can use the default configuration:\n","```\n","env_name = 'CartPole-v0'\n","ep_len = 200\n","batch_size = 1000\n","eval_batch_size =  400\n","n_iter =  100\n","discount =  0.9\n","learning_rate = 5e-3\n","```\n","Then you can try with different variations of updates and gradient steps:\n","```\n","num_target_updates = 1\n","num_grad_steps_per_target_update = 1\n","```\n","In the example above, we alternate between performing one target update and one gradient update step for the critic. As you will see, this probably doesn't work, and you need to increase both the number of target\n","updates and number of gradient updates. Compare the results for the following settings and report which worked best.\n","```\n","num_target_updates = 1\n","num_grad_steps_per_target_update = 100\n","```\n","```\n","num_target_updates = 100\n","num_grad_steps_per_target_update = 1\n","```\n","```\n","num_target_updates = 10\n","num_grad_steps_per_target_update = 10\n","```\n","At the end, the best setting from above should give you a robust performance on Cartpole (reward 200).\n","\n","#3. Run actor-critic with more dificult tasks.\n","Use the best setting from the previous question to run the harder `InvertedPendulumSwingupBulletEnv-v0` which uses a phisics engine and requires to learn the swing up maneouver and the even harder `BipedalWalker-v3` or `HalfCheetah-v4`:\n","\n","For both Bullet-based inverted pendulums, you can use the followind settings:\n","```\n","ep_len = 1000\n","batch_size = 6000\n","eval_batch_size =  500\n","\n","n_iter =  150\n","discount =  0.95\n","learning_rate = 0.005\n","n_layers = 2\n","size =  64\n","```\n","The Mujoco `InvertedPendulum-v4` is slightly easier and can be solved with less iterations and smaller batch size:\n","```\n","ep_len = 1000\n","batch_size = 5000\n","eval_batch_size =  500\n","\n","n_iter =  100\n","discount =  0.95\n","learning_rate = 0.01\n","n_layers = 2\n","size =  64\n","```\n","\n","For halfcheetah, you can use the followind settings:\n","```\n","ep_len = 150\n","batch_size = 30000\n","eval_batch_size =  1500\n","\n","n_iter =  150\n","discount =  0.9\n","learning_rate = 0.02\n","n_layers = 2\n","size =  32\n","```\n","and for the bipedal walker:\n","```\n","ep_len = 1000\n","batch_size = 20000\n","eval_batch_size =  1500\n","\n","n_iter =  200\n","discount =  0.95\n","learning_rate = 0.002\n","n_layers = 4\n","size =  64\n","```\n","For reference, using the HalfCheetah-v4, you should get around 150 of reward after 150 iterations.\n","\n","#4. Submitting the code and experiment runs\n","\n","You need to submit a zip file with the code (.py or .ipynb) and the data generated in the runs.\n","\n","If you submit the ipynb file, you can replace the visualization and tensorboard boxes for text and figures briefly explainin the results (example: average expected reward in multiple runs with different seeds...).\n","\n","If you prefer, you can submit the results (text and figures) in a separated PDF instead.\n","\n","**Note:** Ideally, you should run everything for multiple seeds and see the average outcomes, but for the longer experiments, like the swing up or the bipedal walker, you can just run it once or twice to save time.\n"]},{"cell_type":"code","metadata":{"id":"os8KvMffA1bO","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708965869122,"user_tz":-60,"elapsed":126704,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"25464f64-d019-4619-8967-793ba35c5ce4"},"source":["#@title install dependencies\n","#@markdown it might take a while. Run it as soon as possible.\n","# remove ` > /dev/null 2>&1` to see what is going on under the hood\n","!apt update > /dev/null 2>&1\n","!apt install -y --no-install-recommends \\\n","        swig \\\n","        xvfb \\\n","        libglfw3 \\\n","        libglfw3-dev \\\n","        python3-opengl \\\n","        ffmpeg > /dev/null 2>&1\n","%pip install swig\n","%pip install mujoco==2.2.0 \\\n","  gym[box2d,mujoco]==0.25.2 \\\n","  tensorboardX==2.5.1 \\\n","  pyvirtualdisplay==3.0 \\\n","  opencv-python==4.6.0.66 \\\n","  pybullet > /dev/null 2>&1"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting swig\n","  Downloading swig-4.2.0.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: swig\n","Successfully installed swig-4.2.0.post0\n"]}]},{"cell_type":"code","metadata":{"id":"pkxarnnfWbL2","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708965875844,"user_tz":-60,"elapsed":6740,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"1c547083-d6a1-46a2-ee42-e517a2d94d11"},"source":["#@title imports (torch, numpy, gym, pybullet...)\n","import numpy as np\n","import time\n","import copy\n","import abc\n","import itertools\n","import pickle\n","import os\n","\n","from collections import OrderedDict\n","from typing import Union\n","\n","import torch\n","from torch import nn\n","from torch import distributions\n","from torch import optim\n","from tensorboardX import SummaryWriter\n","\n","import gym\n","import gym.spaces\n","from gym import wrappers\n","\n","import mujoco\n","import pybullet_envs"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:440: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n","  logger.warn(\n"]}]},{"cell_type":"code","metadata":{"id":"8OjiUYyJAR_h","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708965875844,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"164eef7c-322a-4e3c-c910-a1b2a0afc464"},"source":["#@title code to display animations\n","from gym.wrappers import RecordVideo\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","## modified from https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t#scrollTo=TCelFzWY9MBI\n","\n","def show_video():\n","  mp4list = glob.glob('/content/video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else:\n","    print(\"Could not find video\")\n","\n","\n","def wrap_env(env):\n","  env = RecordVideo(env, '/content/video')\n","  return env\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","metadata":{"id":"HgeVEkRSAZvd","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708965876902,"user_tz":-60,"elapsed":1061,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"6bdece55-2c2f-4b61-c859-1b3963175342"},"source":["#@title set up virtual display\n","from pyvirtualdisplay import Display\n","\n","display = Display(visible=0, size=(1400, 900))\n","display.start()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7d0418176230>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"6ZZtPkufAcmt","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"status":"ok","timestamp":1708965880385,"user_tz":-60,"elapsed":3490,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"e2677e92-09d8-468c-b72f-d4a5331678dd"},"source":["#@title test virtual display\n","\n","#@markdown If you see a video of a two-leg-dog fumbling about, setup is complete!\n","\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","env = wrap_env(gym.make(\"HalfCheetah-v4\", render_mode='rgb_array'))\n","\n","observation = env.reset()\n","for i in range(10):\n","    env.render()\n","    obs, rew, term, _ = env.step(env.action_space.sample() )\n","    if term:\n","      break;\n","\n","env.close()\n","print('Loading video...')\n","show_video()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n","/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"output_type":"stream","name":"stdout","text":["Loading video...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"cellView":"form","id":"T5P3pN6i5lus","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708965880386,"user_tz":-60,"elapsed":12,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"92ee09ff-d265-4e94-dc88-c47ebac4d387"},"source":["#@title set-up GPU if available\n","\n","ptu_device = None\n","\n","def ptu_init_gpu(use_gpu=True, gpu_id=0):\n","    global ptu_device\n","    if torch.cuda.is_available() and use_gpu:\n","        ptu_device = torch.device(\"cuda:\" + str(gpu_id))\n","        print(\"Using GPU id {}\".format(gpu_id))\n","    else:\n","        ptu_device = torch.device(\"cpu\")\n","        print(\"GPU not detected. Defaulting to CPU.\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","metadata":{"cellView":"form","id":"5kb0sfwe_zDF","executionInfo":{"status":"ok","timestamp":1708965880386,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title logging tools for tensorboard, video...\n","\n","class Logger:\n","    def __init__(self, log_dir, n_logged_samples=10, summary_writer=None):\n","        self._log_dir = log_dir\n","        print('########################')\n","        print('logging outputs to ', log_dir)\n","        print('########################')\n","        self._n_logged_samples = n_logged_samples\n","        self._summ_writer = SummaryWriter(log_dir, flush_secs=1, max_queue=1)\n","\n","    def log_scalar(self, scalar, name, step_):\n","        self._summ_writer.add_scalar('{}'.format(name), scalar, step_)\n","\n","    def log_scalars(self, scalar_dict, group_name, step, phase):\n","        \"\"\"Will log all scalars in the same plot.\"\"\"\n","        self._summ_writer.add_scalars('{}_{}'.format(group_name, phase), scalar_dict, step)\n","\n","    def log_image(self, image, name, step):\n","        assert(len(image.shape) == 3)  # [C, H, W]\n","        self._summ_writer.add_image('{}'.format(name), image, step)\n","\n","    def log_video(self, video_frames, name, step, fps=10):\n","        assert len(video_frames.shape) == 5, \"Need [N, T, C, H, W] input tensor for video logging!\"\n","        self._summ_writer.add_video('{}'.format(name), video_frames, step, fps=fps)\n","\n","    def log_paths_as_videos(self, paths, step, max_videos_to_save=2, fps=10, video_title='video'):\n","\n","        # reshape the rollouts\n","        videos = [np.transpose(p['image_obs'], [0, 3, 1, 2]) for p in paths]\n","\n","        # max rollout length\n","        max_videos_to_save = np.min([max_videos_to_save, len(videos)])\n","        max_length = videos[0].shape[0]\n","        for i in range(max_videos_to_save):\n","            if videos[i].shape[0]>max_length:\n","                max_length = videos[i].shape[0]\n","\n","        # pad rollouts to all be same length\n","        for i in range(max_videos_to_save):\n","            if videos[i].shape[0]<max_length:\n","                padding = np.tile([videos[i][-1]], (max_length-videos[i].shape[0],1,1,1))\n","                videos[i] = np.concatenate([videos[i], padding], 0)\n","\n","        # log videos to tensorboard event file\n","        videos = np.stack(videos[:max_videos_to_save], 0)\n","        self.log_video(videos, video_title, step, fps=fps)\n","\n","    def log_figures(self, figure, name, step, phase):\n","        \"\"\"figure: matplotlib.pyplot figure handle\"\"\"\n","        assert figure.shape[0] > 0, \"Figure logging requires input shape [batch x figures]!\"\n","        self._summ_writer.add_figure('{}_{}'.format(name, phase), figure, step)\n","\n","    def log_figure(self, figure, name, step, phase):\n","        \"\"\"figure: matplotlib.pyplot figure handle\"\"\"\n","        self._summ_writer.add_figure('{}_{}'.format(name, phase), figure, step)\n","\n","    def log_graph(self, array, name, step, phase):\n","        \"\"\"figure: matplotlib.pyplot figure handle\"\"\"\n","        im = plot_graph(array)\n","        self._summ_writer.add_image('{}_{}'.format(name, phase), im, step)\n","\n","    def dump_scalars(self, log_path=None):\n","        log_path = os.path.join(self._log_dir, \"scalar_data.json\") if log_path is None else log_path\n","        self._summ_writer.export_scalars_to_json(log_path)\n","\n","    def flush(self):\n","        self._summ_writer.flush()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMxvGRY4DaZd","cellView":"form","executionInfo":{"status":"ok","timestamp":1708965880386,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title trajectory sampling functions\n","\n","def sample_trajectory(env, policy, max_path_length, render=False, render_mode=('rgb_array')):\n","\n","    # initialize env for the beginning of a new rollout\n","    ob = env.reset()\n","\n","    # init vars\n","    obs, acs, rewards, next_obs, terminals, image_obs = [], [], [], [], [], []\n","    steps = 0\n","    while True:\n","\n","        # render image of the simulated env\n","        if render:\n","            if 'rgb_array' in render_mode:\n","                if hasattr(env, 'sim'):\n","                    image_obs.append(env.sim.render(camera_name='track', height=500, width=500)[::-1])\n","                else:\n","                    image_obs.append(env.render(mode=render_mode))\n","            if 'human' in render_mode:\n","                env.render(mode=render_mode)\n","                time.sleep(env.model.opt.timestep)\n","\n","        # use the most recent ob to decide what to do\n","        obs.append(ob)\n","        ac = policy.get_action(ob)\n","        ac = ac[0]\n","        acs.append(ac)\n","\n","        # take that action and record results\n","        ob, rew, done, _ = env.step(ac)\n","\n","        # record result of taking that action\n","        steps += 1\n","        next_obs.append(ob)\n","        rewards.append(rew)\n","\n","        # end the rollout if the rollout ended\n","        rollout_done = done or steps >= max_path_length\n","        terminals.append(rollout_done)\n","\n","        if rollout_done:\n","            break\n","\n","    return Path(obs, image_obs, acs, rewards, next_obs, terminals)\n","\n","def sample_trajectories(env, policy, min_timesteps_per_batch, max_path_length, render=False, render_mode=('rgb_array')):\n","    \"\"\"\n","        Collect rollouts until we have collected min_timesteps_per_batch steps.\n","    \"\"\"\n","    timesteps_this_batch = 0\n","    paths = []\n","    while timesteps_this_batch < min_timesteps_per_batch:\n","        path = sample_trajectory(env, policy, max_path_length, render, render_mode)\n","        paths.append(path)\n","        timesteps_this_batch += get_pathlength(path)\n","\n","    return paths, timesteps_this_batch\n","\n","def sample_n_trajectories(env, policy, ntraj, max_path_length, render=False, render_mode=('rgb_array')):\n","    \"\"\"\n","        Collect ntraj rollouts.\n","    \"\"\"\n","\n","    paths = [sample_trajectory(env, policy, max_path_length, render, render_mode)\n","             for _ in range(ntraj)]\n","\n","    return paths\n","\n","def Path(obs, image_obs, acs, rewards, next_obs, terminals):\n","    \"\"\"\n","        Take info (separate arrays) from a single rollout\n","        and return it in a single dictionary\n","    \"\"\"\n","    if image_obs != []:\n","        image_obs = np.stack(image_obs, axis=0)\n","    return {\"observation\" : np.array(obs, dtype=np.float32),\n","            \"image_obs\" : np.array(image_obs, dtype=np.uint8),\n","            \"reward\" : np.array(rewards, dtype=np.float32),\n","            \"action\" : np.array(acs, dtype=np.float32),\n","            \"next_observation\": np.array(next_obs, dtype=np.float32),\n","            \"terminal\": np.array(terminals, dtype=np.float32)}\n","\n","\n","def convert_listofrollouts(paths):\n","    \"\"\"\n","        Take a list of rollout dictionaries\n","        and return separate arrays,\n","        where each array is a concatenation of that array from across the rollouts\n","    \"\"\"\n","    observations = np.concatenate([path[\"observation\"] for path in paths])\n","    actions = np.concatenate([path[\"action\"] for path in paths])\n","    next_observations = np.concatenate([path[\"next_observation\"] for path in paths])\n","    terminals = np.concatenate([path[\"terminal\"] for path in paths])\n","    concatenated_rewards = np.concatenate([path[\"reward\"] for path in paths])\n","    unconcatenated_rewards = [path[\"reward\"] for path in paths]\n","    return observations, actions, next_observations, terminals, concatenated_rewards, unconcatenated_rewards\n","\n","############################################\n","############################################\n","\n","def get_pathlength(path):\n","    return len(path[\"reward\"])\n","\n","def normalize(data, mean, std, eps=1e-8):\n","    return (data-mean)/(std+eps)\n","\n","def unnormalize(data, mean, std):\n","    return data*std+mean\n","\n","def add_noise(data_inp, noiseToSignal=0.01):\n","\n","    data = copy.deepcopy(data_inp) #(num data points, dim)\n","\n","    #mean of data\n","    mean_data = np.mean(data, axis=0)\n","\n","    #if mean is 0,\n","    #make it 0.001 to avoid 0 issues later for dividing by std\n","    mean_data[mean_data == 0] = 0.000001\n","\n","    #width of normal distribution to sample noise from\n","    #larger magnitude number = could have larger magnitude noise\n","    std_of_noise = mean_data * noiseToSignal\n","    for j in range(mean_data.shape[0]):\n","        data[:, j] = np.copy(data[:, j] + np.random.normal(\n","            0, np.absolute(std_of_noise[j]), (data.shape[0],)))\n","\n","    return data\n","\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tm9KXQ2uLm3z","cellView":"form","executionInfo":{"status":"ok","timestamp":1708965880386,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Pytorch tools\n","#@markdown `ptu_build_mlp(..)` build a MLP network \\\\\n","#@markdown `ptu_from_numpy(..)` `ptu_to_numpy(..)` to convert torch.tensor to and from numpy.array\n","\n","Activation = Union[str, nn.Module]\n","\n","\n","_str_to_activation = {\n","    'relu': nn.ReLU(),\n","    'tanh': nn.Tanh(),\n","    'leaky_relu': nn.LeakyReLU(),\n","    'sigmoid': nn.Sigmoid(),\n","    'selu': nn.SELU(),\n","    'softplus': nn.Softplus(),\n","    'identity': nn.Identity(),\n","}\n","\n","\n","def ptu_build_mlp(\n","        input_size: int,\n","        output_size: int,\n","        n_layers: int,\n","        size: int,\n","        activation: Activation = 'tanh',\n","        output_activation: Activation = 'identity',\n","):\n","    \"\"\"\n","        Builds a feedforward neural network\n","        arguments:\n","            input_placeholder: placeholder variable for the state (batch_size, input_size)\n","            scope: variable scope of the network\n","            n_layers: number of hidden layers\n","            size: dimension of each hidden layer\n","            activation: activation of each hidden layer\n","            input_size: size of the input layer\n","            output_size: size of the output layer\n","            output_activation: activation of the output layer\n","        returns:\n","            output_placeholder: the result of a forward pass through the hidden layers + the output layer\n","    \"\"\"\n","    if isinstance(activation, str):\n","        activation = _str_to_activation[activation]\n","    if isinstance(output_activation, str):\n","        output_activation = _str_to_activation[output_activation]\n","    layers = []\n","    in_size = input_size\n","    for _ in range(n_layers):\n","        layers.append(nn.Linear(in_size, size))\n","        layers.append(activation)\n","        in_size = size\n","    layers.append(nn.Linear(in_size, output_size))\n","    layers.append(output_activation)\n","    return nn.Sequential(*layers)\n","\n","\n","def ptu_from_numpy(*args, **kwargs):\n","    return torch.from_numpy(*args, **kwargs).float().to(ptu_device)\n","\n","\n","def ptu_to_numpy(tensor):\n","    return tensor.to('cpu').detach().numpy()\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"nAwhF4VZQLp8","cellView":"form","executionInfo":{"status":"ok","timestamp":1708965880386,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Replay buffer\n","class ReplayBuffer(object):\n","\n","    def __init__(self, max_size=1000000):\n","\n","        self.max_size = max_size\n","        self.paths = []\n","        self.obs = None\n","        self.acs = None\n","        self.concatenated_rews = None\n","        self.next_obs = None\n","        self.terminals = None\n","\n","    def add_rollouts(self, paths, noised=False):\n","\n","        # add new rollouts into our list of rollouts\n","        for path in paths:\n","            self.paths.append(path)\n","\n","        # convert new rollouts into their component arrays, and append them onto our arrays\n","        observations, actions, next_observations, terminals, concatenated_rews, unconcatenated_rews = convert_listofrollouts(paths)\n","\n","        if noised:\n","            observations = add_noise(observations)\n","            next_observations = add_noise(next_observations)\n","\n","        if self.obs is None:\n","            self.obs = observations[-self.max_size:]\n","            self.acs = actions[-self.max_size:]\n","            self.next_obs = next_observations[-self.max_size:]\n","            self.terminals = terminals[-self.max_size:]\n","            self.concatenated_rews = concatenated_rews[-self.max_size:]\n","        else:\n","            self.obs = np.concatenate([self.obs, observations])[-self.max_size:]\n","            self.acs = np.concatenate([self.acs, actions])[-self.max_size:]\n","            self.next_obs = np.concatenate(\n","                [self.next_obs, next_observations]\n","            )[-self.max_size:]\n","            self.terminals = np.concatenate(\n","                [self.terminals, terminals]\n","            )[-self.max_size:]\n","            self.concatenated_rews = np.concatenate(\n","                [self.concatenated_rews, concatenated_rews]\n","            )[-self.max_size:]\n","\n","\n","    def sample_random_rollouts(self, num_rollouts):\n","\n","        rand_indices = np.random.permutation(len(self.paths))[:num_rollouts]\n","        return self.paths[rand_indices]\n","\n","\n","    def sample_recent_rollouts(self, num_rollouts=1):\n","\n","        return self.paths[-num_rollouts:]\n","\n","\n","    def sample_random_data(self, batch_size):\n","\n","        assert self.obs.shape[0] == self.acs.shape[0] == self.concatenated_rews.shape[0] == self.next_obs.shape[0] == self.terminals.shape[0]\n","        rand_indices = np.random.permutation(self.obs.shape[0])[:batch_size]\n","        return self.obs[rand_indices], self.acs[rand_indices], self.concatenated_rews[rand_indices], self.next_obs[rand_indices], self.terminals[rand_indices]\n","\n","\n","    def sample_recent_data(self, batch_size=1, concat_rew=True):\n","\n","        if concat_rew:\n","            return self.obs[-batch_size:], self.acs[-batch_size:], self.concatenated_rews[-batch_size:], self.next_obs[-batch_size:], self.terminals[-batch_size:]\n","        else:\n","            num_recent_rollouts_to_return = 0\n","            num_datapoints_so_far = 0\n","            index = -1\n","            while num_datapoints_so_far < batch_size:\n","                recent_rollout = self.paths[index]\n","                index -=1\n","                num_recent_rollouts_to_return +=1\n","                num_datapoints_so_far += get_pathlength(recent_rollout)\n","            rollouts_to_return = self.paths[-num_recent_rollouts_to_return:]\n","            observations, actions, next_observations, terminals, concatenated_rews, unconcatenated_rews = convert_listofrollouts(rollouts_to_return)\n","            return observations, actions, unconcatenated_rews, next_observations, terminals"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xbsni0fwC1k8","executionInfo":{"status":"ok","timestamp":1708965880387,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Critic\n","#@markdown You need to code the critic `update(..)` function\n","\n","class BaseCritic(object):\n","    def update(self, ob_no, ac_na, next_ob_no, re_n, terminal_n):\n","        raise NotImplementedError\n","\n","class BootstrappedContinuousCritic(nn.Module, BaseCritic):\n","    \"\"\"\n","        Notes on notation:\n","\n","        Prefixes and suffixes:\n","        ob - observation\n","        ac - action\n","        _no - this tensor should have shape (batch self.size /n/, observation dim)\n","        _na - this tensor should have shape (batch self.size /n/, action dim)\n","        _n  - this tensor should have shape (batch self.size /n/)\n","\n","        Note: batch self.size /n/ is defined at runtime.\n","        is None\n","    \"\"\"\n","    def __init__(self, hparams):\n","        super().__init__()\n","        self.ob_dim = hparams['ob_dim']\n","        self.ac_dim = hparams['ac_dim']\n","        self.discrete = hparams['discrete']\n","        self.size = hparams['size']\n","        self.n_layers = hparams['n_layers']\n","        self.learning_rate = hparams['learning_rate']\n","\n","        # critic parameters\n","        self.num_target_updates = hparams['num_target_updates']\n","        self.num_grad_steps_per_target_update = hparams['num_grad_steps_per_target_update']\n","        self.gamma = hparams['gamma']\n","        self.critic_network = ptu_build_mlp(\n","            self.ob_dim,\n","            1,\n","            n_layers=self.n_layers,\n","            size=self.size,\n","        )\n","        self.critic_network.to(ptu_device)\n","        self.loss = nn.MSELoss()\n","        self.optimizer = optim.Adam(\n","            self.critic_network.parameters(),\n","            self.learning_rate,\n","        )\n","\n","    def forward(self, obs):\n","        return self.critic_network(obs).squeeze(1)\n","\n","    def forward_np(self, obs):\n","        obs = ptu_from_numpy(obs)\n","        predictions = self(obs)\n","        return ptu_to_numpy(predictions)\n","\n","    def update(self, ob_no, ac_na, next_ob_no, reward_n, terminal_n):\n","        \"\"\"\n","            Update the parameters of the critic.\n","\n","            let sum_of_path_lengths be the sum of the lengths of the paths sampled from\n","                Agent.sample_trajectories\n","            let num_paths be the number of paths sampled from Agent.sample_trajectories\n","\n","            arguments:\n","                ob_no: shape: (sum_of_path_lengths, ob_dim)\n","                next_ob_no: shape: (sum_of_path_lengths, ob_dim). The observation after taking one step forward\n","                reward_n: length: sum_of_path_lengths. Each element in reward_n is a scalar containing\n","                    the reward for each timestep\n","                terminal_n: length: sum_of_path_lengths. Each element in terminal_n is either 1 if the episode ended\n","                    at that timestep of 0 if the episode did not end\n","\n","            returns:\n","                training loss\n","        \"\"\"\n","        # Implement the pseudocode below: do the following\n","        # (self.num_target_updates * self.num_grad_steps_per_target_update) times:\n","        # every self.num_target_updates (which includes the first time),\n","        # recompute the target values by\n","        #     a) calculating V(s') by querying the critic with next_ob_no\n","        #     b) and computing the target values as r(s, a) + gamma * V(s')\n","        # every time, update this critic using the observations and targets\n","        #     c) compute the loss/backward pass and perform as many grad steps\n","        # as indicated by self.num_grad_steps_per_target_update.\n","        # HINT: don't forget to use terminal_n to cut off the V(s') (ie set it\n","        #       to 0) when a terminal state is reached\n","        # HINT: make sure to squeeze the output of the critic_network to ensure\n","        #       that its dimensions match the reward\n","        # HINT: remember that pytorch accumulate gradients. You can use zero_grad\n","        #       to reinitialize the gradient before/after any step.\n","\n","        # Comment this is you prefer to work with numpy arrays or pytorch tensors\n","        ob_no = ptu_from_numpy(ob_no)\n","        next_ob_no = ptu_from_numpy(next_ob_no)\n","        reward_n = ptu_from_numpy(reward_n)\n","        terminal_n = ptu_from_numpy(terminal_n).bool()\n","\n","        TODO\n","        v = self.forward(...)\n","\n","        v = v.detach() #pytorch Tensors\n","\n","        v = v.copy() #numpy array\n","\n","        self.optimizer.zero_grad()\n","        #my computations\n","        loss = self.loss(...)\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        v2 = self.forward(...)\n","\n","        return loss.item()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pri5XwNyDp9J","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"error","timestamp":1708965880387,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}},"outputId":"1a6658a5-1800-48de-a84c-857b45c1c9d4"},"source":["#@title Policy (actor)\n","#@markdown You need to code the policy `update(..)` function\n","\n","class BasePolicy(object, metaclass=abc.ABCMeta):\n","    def get_action(self, obs):\n","        raise NotImplementedError\n","\n","    def update(self, obs, acs, **kwargs):\n","        \"\"\"Return a dictionary of logging information.\"\"\"\n","        raise NotImplementedError\n","\n","    def save(self, filepath):\n","        raise NotImplementedError\n","\n","\n","class MLPPolicy(BasePolicy, nn.Module, metaclass=abc.ABCMeta):\n","\n","    def __init__(self,\n","                 ac_dim,\n","                 ob_dim,\n","                 n_layers,\n","                 size,\n","                 discrete=False,\n","                 learning_rate=1e-4,\n","                 training=True,\n","                 nn_baseline=False,\n","                 **kwargs\n","                 ):\n","        super().__init__(**kwargs)\n","\n","        # init vars\n","        self.ac_dim = ac_dim\n","        self.ob_dim = ob_dim\n","        self.n_layers = n_layers\n","        self.discrete = discrete\n","        self.size = size\n","        self.learning_rate = learning_rate\n","        self.training = training\n","        self.nn_baseline = nn_baseline\n","\n","        if self.discrete:\n","            self.logits_na = ptu_build_mlp(input_size=self.ob_dim,\n","                                           output_size=self.ac_dim,\n","                                           n_layers=self.n_layers,\n","                                           size=self.size)\n","            self.logits_na.to(ptu_device)\n","            self.mean_net = None\n","            self.logstd = None\n","            self.optimizer = optim.Adam(self.logits_na.parameters(),\n","                                        self.learning_rate)\n","        else:\n","            self.logits_na = None\n","            self.mean_net = ptu_build_mlp(input_size=self.ob_dim,\n","                                      output_size=self.ac_dim,\n","                                      n_layers=self.n_layers, size=self.size)\n","            self.logstd = nn.Parameter(\n","                torch.zeros(self.ac_dim, dtype=torch.float32, device=ptu_device)\n","            )\n","            self.mean_net.to(ptu_device)\n","            self.logstd.to(ptu_device)\n","            self.optimizer = optim.Adam(\n","                itertools.chain([self.logstd], self.mean_net.parameters()),\n","                self.learning_rate\n","            )\n","\n","        if nn_baseline:\n","            self.baseline = ptu_build_mlp(\n","                input_size=self.ob_dim,\n","                output_size=1,\n","                n_layers=self.n_layers,\n","                size=self.size,\n","            )\n","            self.baseline.to(ptu_device)\n","            self.baseline_optimizer = optim.Adam(\n","                self.baseline.parameters(),\n","                self.learning_rate,\n","            )\n","        else:\n","            self.baseline = None\n","\n","    ##################################\n","\n","    def save(self, filepath):\n","        torch.save(self.state_dict(), filepath)\n","\n","    ##################################\n","\n","    # query the policy with observation(s) to get selected action(s)\n","    def get_action(self, obs: np.ndarray) -> np.ndarray:\n","        if len(obs.shape) > 1:\n","            observation = obs\n","        else:\n","            observation = obs[None]\n","\n","        observation_tensor = torch.tensor(observation, dtype=torch.float).to(ptu_device)\n","        action_distribution = self.forward(observation_tensor)\n","        return ptu_to_numpy(action_distribution.sample())\n","\n","\n","    # update/train this policy\n","    def update(self, observations_np, actions_np, advantages_np=None):\n","\n","        # Comment this is you prefer to work with numpy arrays or pytorch tensors\n","        observations = ptu_from_numpy(observations_np)\n","        actions = ptu_from_numpy(actions_np)\n","        advantages = ptu_from_numpy(advantages_np)\n","\n","        # Compute the loss that should be optimized when training with policy gradient\n","        # HINT1: Recall that the expression that we want to MAXIMIZE\n","            # is the expectation over collected trajectories of:\n","            # sum_{t=0}^{T-1} [grad [log pi(a_t|s_t) * A_t ]]\n","        # HINT2: you will want to use the `log_prob` method on the distribution returned\n","            # by the `forward` method\n","        # HINT3: don't forget that `optimizer.step()` MINIMIZES a loss\n","\n","        TODO\n","        lp = self.forward(....).log_prob(...)\n","\n","        if not self.discrete:\n","            lp = lp.sum(1)\n","\n","        loss = # grad equation\n","\n","        # Optimize `loss` using `self.optimizer`\n","        # HINT: remember to `zero_grad` first\n","        TODO\n","\n","        return loss.item()\n","\n","    # This function defines the forward pass of the network. It returns\n","    # `torch.distributions.Distribution` objects which allows quite flexibility.\n","    def forward(self, observation: torch.Tensor):\n","        if self.discrete:\n","            return distributions.Categorical(logits=self.logits_na(observation))\n","        else:\n","            assert self.logstd is not None\n","            return distributions.Normal(\n","                self.mean_net(observation),\n","                torch.exp(self.logstd)[None],\n","            )"],"execution_count":12,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-12-0278ef3762c6>, line 117)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-0278ef3762c6>\"\u001b[0;36m, line \u001b[0;32m117\u001b[0m\n\u001b[0;31m    lp = self.forward(....).log_prob(...)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"SWqbVw-bCJbq","executionInfo":{"status":"aborted","timestamp":1708965880389,"user_tz":-60,"elapsed":139345,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Actor-Critic agent\n","#@markdown We have all the ingredientes (actor, critic, replay bufffer...). Let's put all together.\n","#@markdown You need to code the `estimate_advantage(..)` function\n","\n","class BaseAgent(object):\n","    def __init__(self, **kwargs):\n","        super(BaseAgent, self).__init__(**kwargs)\n","\n","    def train(self) -> dict:\n","        \"\"\"Return a dictionary of logging information.\"\"\"\n","        raise NotImplementedError\n","\n","    def add_to_replay_buffer(self, paths):\n","        raise NotImplementedError\n","\n","    def sample(self, batch_size):\n","        raise NotImplementedError\n","\n","    def save(self, path):\n","        raise NotImplementedError\n","\n","class ACAgent(BaseAgent):\n","    def __init__(self, env, agent_params):\n","        super(ACAgent, self).__init__()\n","\n","        self.env = env\n","        self.agent_params = agent_params\n","\n","        self.gamma = self.agent_params['gamma']\n","        self.standardize_advantages = self.agent_params['standardize_advantages']\n","\n","        self.actor = MLPPolicy(\n","            self.agent_params['ac_dim'],\n","            self.agent_params['ob_dim'],\n","            self.agent_params['n_layers'],\n","            self.agent_params['size'],\n","            self.agent_params['discrete'],\n","            self.agent_params['learning_rate'],\n","        )\n","        self.critic = BootstrappedContinuousCritic(self.agent_params)\n","\n","        self.replay_buffer = ReplayBuffer()\n","\n","    def train(self, ob_no, ac_na, re_n, next_ob_no, terminal_n):\n","        # for agent_params['num_critic_updates_per_agent_update'] steps,\n","        #     update the critic\n","\n","        loss = OrderedDict()\n","\n","        for _ in range(self.agent_params['num_critic_updates_per_agent_update']):\n","            loss['Critic_Loss'] = self.critic.update(\n","                ob_no, ac_na, next_ob_no, re_n, terminal_n)\n","\n","        advantages = self.estimate_advantage(ob_no, next_ob_no, re_n, terminal_n)\n","\n","        # for agent_params['num_actor_updates_per_agent_update'] steps,\n","        #     update the actor\n","        for _ in range(self.agent_params['num_actor_updates_per_agent_update']):\n","            loss['Actor_Loss'] = self.actor.update(\n","                ob_no, ac_na, advantages)\n","\n","        return loss\n","\n","    def estimate_advantage(self, ob_no, next_ob_no, re_n, terminal_n):\n","        # Implement the following pseudocode:\n","        # 1) query the critic with ob_no, to get V(s)\n","        # 2) query the critic with next_ob_no, to get V(s')\n","        # 3) estimate the Q value as Q(s, a) = r(s, a) + gamma*V(s')\n","        # HINT: Remember to cut off the V(s') term (ie set it to 0) at terminal states (ie terminal_n=1)\n","        # 4) calculate advantage (adv_n) as A(s, a) = Q(s, a) - V(s)\n","\n","        # Comment this is you prefer to work with numpy arrays or pytorch tensors\n","        ob_no = ptu_from_numpy(ob_no)\n","        next_ob_no = ptu_from_numpy(next_ob_no)\n","        re_n = ptu_from_numpy(re_n)\n","        terminal_n = ptu_from_numpy(terminal_n).bool()\n","\n","        TODO\n","\n","        if self.standardize_advantages:\n","            adv_n = (adv_n - np.mean(adv_n)) / (np.std(adv_n) + 1e-8)\n","        return adv_n\n","\n","    def add_to_replay_buffer(self, paths):\n","        self.replay_buffer.add_rollouts(paths)\n","\n","    def sample(self, batch_size):\n","        return self.replay_buffer.sample_recent_data(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0eM0afBHHfP","executionInfo":{"status":"aborted","timestamp":1708965880767,"user_tz":-60,"elapsed":12,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Define RL_trainer to perform the control loop\n","#@markdown It takes care to collect data, update networks, manage environement, logs...\n","\n","from tqdm import tqdm_notebook\n","\n","# how many rollouts to save as videos to tensorboard\n","MAX_NVIDEO = 2\n","MAX_VIDEO_LEN = 40 # we overwrite this in the code below\n","\n","\n","class RL_Trainer(object):\n","\n","    def __init__(self, params):\n","\n","        #############\n","        ## INIT\n","        #############\n","\n","        # Get params, create logger\n","        self.params = params\n","        self.logger = Logger(self.params['logdir'])\n","\n","        # Set random seeds\n","        seed = self.params['seed']\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","        ptu_init_gpu(\n","            use_gpu=not self.params['no_gpu'],\n","            gpu_id=self.params['which_gpu']\n","        )\n","\n","        #############\n","        ## ENV\n","        #############\n","\n","        # Make the gym environment\n","        self.env = gym.make(self.params['env_name'])\n","        self.env.seed(seed)\n","\n","        # Maximum length for episodes\n","        self.params['ep_len'] = self.params['ep_len'] or self.env.spec.max_episode_steps\n","        global MAX_VIDEO_LEN\n","        MAX_VIDEO_LEN = self.params['ep_len']\n","\n","        # Is this env continuous, or self.discrete?\n","        discrete = isinstance(self.env.action_space, gym.spaces.Discrete)\n","        # Are the observations images?\n","        img = len(self.env.observation_space.shape) > 2\n","\n","        self.params['agent_params']['discrete'] = discrete\n","\n","        # Observation and action sizes\n","\n","        ob_dim = self.env.observation_space.shape if img else self.env.observation_space.shape[0]\n","        ac_dim = self.env.action_space.n if discrete else self.env.action_space.shape[0]\n","        self.params['agent_params']['ac_dim'] = ac_dim\n","        self.params['agent_params']['ob_dim'] = ob_dim\n","\n","        # simulation timestep, will be used for video saving\n","        if 'model' in dir(self.env):\n","            self.fps = 1/self.env.model.opt.timestep\n","        elif 'video.frames_per_second' in self.env.env.metadata.keys():\n","            self.fps = self.env.env.metadata['video.frames_per_second']\n","        else:\n","            self.fps = 10\n","\n","\n","        #############\n","        ## AGENT\n","        #############\n","\n","        agent_class = self.params['agent_class']\n","        self.agent = agent_class(self.env, self.params['agent_params'])\n","\n","    def run_training_loop(self, n_iter, collect_policy, eval_policy,\n","                          initial_expertdata=None, relabel_with_expert=False,\n","                          start_relabel_with_expert=1, expert_policy=None):\n","        \"\"\"\n","        :param n_iter:  number of iterations\n","        :param collect_policy:\n","        :param eval_policy:\n","        \"\"\"\n","\n","        # init vars at beginning of training\n","        self.total_envsteps = 0\n","        self.start_time = time.time()\n","\n","        print_period = 1\n","\n","        for itr in tqdm_notebook(range(n_iter), desc='Training'):\n","            if itr % print_period == 0:\n","                print(\"\\n********** Iteration \", itr, \" of \", n_iter, \"************\")\n","\n","            # decide if videos should be rendered/logged at this iteration\n","            if itr % self.params['video_log_freq'] == 0 and self.params['video_log_freq'] != -1:\n","                self.logvideo = True\n","            else:\n","                self.logvideo = False\n","\n","            # decide if metrics should be logged\n","            if self.params['scalar_log_freq'] == -1:\n","                self.logmetrics = False\n","            elif itr % self.params['scalar_log_freq'] == 0:\n","                self.logmetrics = True\n","            else:\n","                self.logmetrics = False\n","\n","            use_batchsize = self.params['batch_size']\n","            if itr==0:\n","                use_batchsize = self.params['batch_size_initial']\n","            paths, envsteps_this_batch, train_video_paths = (\n","                self.collect_training_trajectories(\n","                    itr, collect_policy, use_batchsize)\n","            )\n","\n","            self.total_envsteps += envsteps_this_batch\n","\n","            # relabel the collected obs with actions from a provided expert policy\n","            if relabel_with_expert and itr>=start_relabel_with_expert:\n","                paths = self.do_relabel_with_expert(expert_policy, paths)\n","\n","            # add collected data to replay buffer\n","            self.agent.add_to_replay_buffer(paths)\n","\n","            # train agent (using sampled data from replay buffer)\n","            if itr % print_period == 0:\n","                print(\"\\nTraining agent...\")\n","            all_logs = self.train_agent()\n","\n","            # log/save\n","            if self.logvideo or self.logmetrics:\n","                self.perform_logging(itr, paths, eval_policy, train_video_paths, all_logs)\n","\n","                if self.params['save_params']:\n","                    self.agent.save('{}/agent_itr_{}.pt'.format(self.params['logdir'], itr))\n","\n","    ####################################\n","    ####################################\n","    def collect_training_trajectories(self, itr, collect_policy, batch_size, save_expert_data_to_disk=False):\n","        \"\"\"\n","        :param itr:\n","        :param collect_policy:  the current policy using which we collect data\n","        :param batch_size:  the number of transitions we collect\n","        :return:\n","            paths: a list trajectories\n","            envsteps_this_batch: the sum over the numbers of environment steps in paths\n","            train_video_paths: paths which also contain videos for visualization purposes\n","        \"\"\"\n","\n","        print(\"\\nCollecting data to be used for training...\")\n","        envsteps_this_batch = 0\n","        paths = []\n","        while envsteps_this_batch <= batch_size:\n","            paths.extend(sample_n_trajectories(\n","                    self.env,\n","                    collect_policy,\n","                    max((batch_size - envsteps_this_batch) // self.params['ep_len'], 1),\n","                    max_path_length=self.params['ep_len'],\n","                ))\n","            envsteps_this_batch = sum(path['observation'].shape[0] for path in paths)\n","\n","        # collect more rollouts with the same policy, to be saved as videos in tensorboard\n","        # note: here, we collect MAX_NVIDEO rollouts, each of length MAX_VIDEO_LEN\n","        train_video_paths = None\n","        if self.logvideo:\n","            print('\\nCollecting train rollouts to be used for saving videos...')\n","            train_video_paths = sample_n_trajectories(self.env, collect_policy, MAX_NVIDEO, MAX_VIDEO_LEN, True)\n","\n","        return paths, envsteps_this_batch, train_video_paths\n","\n","    def train_agent(self):\n","        # print('\\nTraining agent using sampled data from replay buffer...')\n","        all_logs = []\n","        for train_step in range(self.params['num_agent_train_steps_per_iter']):\n","            # Sample some data from the data buffer\n","            ob_batch, ac_batch, re_batch, next_ob_batch, terminal_batch = \\\n","                self.agent.sample(self.params['train_batch_size'])\n","\n","            # Use the sampled data to train an agent\n","            train_log = self.agent.train(\n","                ob_batch, ac_batch, re_batch, next_ob_batch, terminal_batch)\n","            all_logs.append(train_log)\n","        return all_logs\n","\n","    ####################################\n","    ####################################\n","    def perform_logging(self, itr, paths, eval_policy, train_video_paths, all_logs):\n","\n","        last_log = all_logs[-1]\n","\n","        #######################\n","\n","        # collect eval trajectories, for logging\n","        print(\"\\nCollecting data for eval...\")\n","        eval_paths, eval_envsteps_this_batch = sample_trajectories(self.env, eval_policy, self.params['eval_batch_size'], self.params['ep_len'])\n","\n","        # save eval rollouts as videos in tensorboard event file\n","        if self.logvideo and train_video_paths != None:\n","            print('\\nCollecting video rollouts eval')\n","            eval_video_paths = sample_n_trajectories(self.env, eval_policy, MAX_NVIDEO, MAX_VIDEO_LEN, True)\n","\n","            #save train/eval videos\n","            print('\\nSaving train rollouts as videos...')\n","            self.logger.log_paths_as_videos(train_video_paths, itr, fps=self.fps, max_videos_to_save=MAX_NVIDEO,\n","                                            video_title='train_rollouts')\n","            self.logger.log_paths_as_videos(eval_video_paths, itr, fps=self.fps,max_videos_to_save=MAX_NVIDEO,\n","                                             video_title='eval_rollouts')\n","\n","        #######################\n","\n","        # save eval metrics\n","        if self.logmetrics:\n","            # returns, for logging\n","            train_returns = [path[\"reward\"].sum() for path in paths]\n","            eval_returns = [eval_path[\"reward\"].sum() for eval_path in eval_paths]\n","\n","            # episode lengths, for logging\n","            train_ep_lens = [len(path[\"reward\"]) for path in paths]\n","            eval_ep_lens = [len(eval_path[\"reward\"]) for eval_path in eval_paths]\n","\n","            # decide what to log\n","            logs = OrderedDict()\n","            logs[\"Eval_AverageReturn\"] = np.mean(eval_returns)\n","            logs[\"Eval_StdReturn\"] = np.std(eval_returns)\n","            logs[\"Eval_MaxReturn\"] = np.max(eval_returns)\n","            logs[\"Eval_MinReturn\"] = np.min(eval_returns)\n","            logs[\"Eval_AverageEpLen\"] = np.mean(eval_ep_lens)\n","\n","            logs[\"Train_AverageReturn\"] = np.mean(train_returns)\n","            logs[\"Train_StdReturn\"] = np.std(train_returns)\n","            logs[\"Train_MaxReturn\"] = np.max(train_returns)\n","            logs[\"Train_MinReturn\"] = np.min(train_returns)\n","            logs[\"Train_AverageEpLen\"] = np.mean(train_ep_lens)\n","\n","            logs[\"Train_EnvstepsSoFar\"] = self.total_envsteps\n","            logs[\"TimeSinceStart\"] = time.time() - self.start_time\n","            logs.update(last_log)\n","\n","            if itr == 0:\n","                self.initial_return = np.mean(train_returns)\n","            logs[\"Initial_DataCollection_AverageReturn\"] = self.initial_return\n","\n","            # perform the logging\n","            for key, value in logs.items():\n","                print('{} : {}'.format(key, value))\n","                self.logger.log_scalar(value, key, itr)\n","            print('Done logging...\\n\\n')\n","\n","            self.logger.flush()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SqKtHSIOoXb","executionInfo":{"status":"aborted","timestamp":1708965880768,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title runtime arguments\n","\n","class ACArgs:\n","\n","  def __getitem__(self, key):\n","    return getattr(self, key)\n","\n","  def __setitem__(self, key, val):\n","    setattr(self, key, val)\n","\n","  def __contains__(self, key):\n","    return hasattr(self, key)\n","\n","  env_name = 'CartPole-v0' #@param ['CartPole-v0', 'HalfCheetah-v4', 'InvertedPendulum-v4', 'InvertedPendulumBulletEnv-v0', 'InvertedPendulumSwingupBulletEnv-v0', 'BipedalWalker-v3']\n","\n","  ## Check the intro on how to set ep_len\n","  ## and discount for each environment\n","  ep_len = 200 #@param {type: \"integer\"}\n","\n","  #@markdown batches and steps\n","  batch_size = 1000 #@param {type: \"integer\"}\n","  eval_batch_size =  400#@param {type: \"integer\"}\n","\n","  n_iter =  100#@param {type: \"integer\"}\n","  num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n","  num_actor_updates_per_agent_update = 1 #@param {type: \"integer\"}\n","  num_critic_updates_per_agent_update = 1 #@param {type: \"integer\"}\n","\n","  #@markdown Actor-Critic parameters\n","  discount =  0.9#@param {type: \"number\"}\n","  learning_rate = 5e-3 #@param {type: \"number\"}\n","  dont_standardize_advantages = False #@param {type: \"boolean\"}\n","  num_target_updates = 10 #@param {type: \"integer\"}\n","  num_grad_steps_per_target_update = 10 #@param {type: \"integer\"}\n","  n_layers = 2 #@param {type: \"integer\"}\n","  size =  64#@param {type: \"integer\"}\n","\n","  #@markdown system\n","  save_params = True #@param {type: \"boolean\"}\n","  no_gpu = False #@param {type: \"boolean\"}\n","  which_gpu = 0 #@param {type: \"integer\"}\n","  seed = 1 #@param {type: \"integer\"}\n","\n","  #@markdown logging\n","  ## default is to not log video so\n","  ## that logs are small enough\n","  video_log_freq =  -1#@param {type: \"integer\"}\n","  scalar_log_freq = 10 #@param {type: \"integer\"}\n","\n","\n","args = ACArgs()\n","\n","\n","if args['video_log_freq'] > 0:\n","  import warnings\n","  warnings.warn(\n","      '''\\nLogging videos will make eventfiles too large.'''\n","      '''\\nSet video_log_freq = -1 to avoid that.''')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZW8OEuMOwC7","cellView":"form","executionInfo":{"status":"aborted","timestamp":1708965880769,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Define AC trainer\n","#@markdown This calls the RL_trainer with the specific parameters for Actor-Critic\n","\n","class AC_Trainer(object):\n","\n","    def __init__(self, params):\n","\n","        #####################\n","        ## SET AGENT PARAMS\n","        #####################\n","\n","        computation_graph_args = {\n","            'n_layers': params['n_layers'],\n","            'size': params['size'],\n","            'learning_rate': params['learning_rate'],\n","            'num_target_updates': params['num_target_updates'],\n","            'num_grad_steps_per_target_update': params['num_grad_steps_per_target_update'],\n","            }\n","\n","        estimate_advantage_args = {\n","            'gamma': params['discount'],\n","            'standardize_advantages': not(params['dont_standardize_advantages']),\n","        }\n","\n","        train_args = {\n","            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n","            'num_critic_updates_per_agent_update': params['num_critic_updates_per_agent_update'],\n","            'num_actor_updates_per_agent_update': params['num_actor_updates_per_agent_update'],\n","        }\n","\n","        agent_params = {**computation_graph_args, **estimate_advantage_args, **train_args}\n","\n","        self.params = params\n","        self.params['agent_class'] = ACAgent\n","        self.params['agent_params'] = agent_params\n","        self.params['train_batch_size'] = params['batch_size']\n","        self.params['batch_size_initial'] = self.params['batch_size']\n","        self.params['non_atari_colab_env'] = True\n","\n","        ################\n","        ## RL TRAINER\n","        ################\n","\n","        self.rl_trainer = RL_Trainer(self.params)\n","\n","    def run_training_loop(self):\n","\n","        self.rl_trainer.run_training_loop(\n","            self.params['n_iter'],\n","            collect_policy = self.rl_trainer.agent.actor,\n","            eval_policy = self.rl_trainer.agent.actor,\n","            )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_i_umdGO5dp","executionInfo":{"status":"aborted","timestamp":1708965880769,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Create directories for logging\n","\n","data_path = '''/content/data'''\n","\n","if not (os.path.exists(data_path)):\n","    os.makedirs(data_path)\n","\n","logdir = 'ac_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n","logdir = os.path.join(data_path, logdir)\n","args['logdir'] = logdir\n","if not(os.path.exists(logdir)):\n","    os.makedirs(logdir)\n","\n","print(\"LOGGING TO: \", logdir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVEA-Ub1PIM6","cellView":"form","executionInfo":{"status":"aborted","timestamp":1708965880770,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Tensorboard panel\n","#@markdown You can visualize your runs with tensorboard from within the notebook\n","\n","#@markdown You might need to refresh the panel after you start training\n","\n","## requires tensorflow==2.3.0\n","%load_ext tensorboard\n","%tensorboard --logdir /content/data/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_EsX40XPEM3","cellView":"form","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1708965880770,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title run training\n","trainer = AC_Trainer(args)\n","trainer.run_training_loop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mn8j7A2sJu9","cellView":"form","executionInfo":{"status":"aborted","timestamp":1708965880770,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Visualize a test run on video\n","if args['env_name'] in ['InvertedPendulumBulletEnv-v0', 'InvertedPendulumSwingupBulletEnv-v0']:\n","  env = wrap_env(gym.make(args['env_name']))\n","else:\n","  env = wrap_env(gym.make(args['env_name'], render_mode='rgb_array'))\n","\n","\n","obs = env.reset()\n","term = False\n","i = 0\n","while not term:\n","    i += 1\n","    if args['env_name'] in ['InvertedPendulumBulletEnv-v0', 'InvertedPendulumSwingupBulletEnv-v0']:\n","      env.render(mode='rgb_array')\n","    else:\n","      env.render()\n","    obs, rew, term, _ = env.step(trainer.rl_trainer.agent.actor.get_action(obs)[0])\n","    if term:\n","      break;\n","\n","env.close()\n","print('Loading video...',i)\n","show_video()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"0_WnmnjOPUAe","executionInfo":{"status":"aborted","timestamp":1708965880771,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"source":["#@title Download results\n","#@markdown Download the content of data the folder in a zip file\n","\n","!zip -r /content/data.zip /content/data\n","\n","from google.colab import files\n","files.download(\"/content/data.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Code to plot different metrics\n","#@markdown This is just an example of the things you can do.\n","#@markdown You might need to change the tag selected, the labels,\n","#@markdown the file names, etc.\n","\n","#@markdown **IMPORTANT:** If you run the same experiment multiple times, this will\n","#@markdown also plot error bars, but remmember to **change the seed** of the random\n","#@markdown number generator.\n","\n","#@markdown You can also run this cell in a separate colab where you upload the\n","#@markdown data folder (see https://colab.research.google.com/notebooks/io.ipynb#scrollTo=BaCkyg5CV5jF)\n","\n","# Plotting example requires tensorflow==1.12.0\n","\n","import glob\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def get_section_results(files, tag):\n","    data = []\n","    for file in files:\n","        row = []\n","        for e in tf.compat.v1.train.summary_iterator(file):\n","            for v in e.summary.value:\n","                if v.tag == tag:\n","                    row.append(v.simple_value)\n","        data.append(row)\n","    return data\n","\n","\n","#logfile = 'data/my_experiment/events*'\n","all_logdir= data_path+'/ac_' + args.env_name + '_*'\n","logfile = all_logdir+'/events*'\n","eventfiles = glob.glob(logfile)\n","\n","tag = 'Train_AverageReturn'\n","X = get_section_results(eventfiles, tag)\n","for j, row in enumerate(X):\n","    for i, x in enumerate(row):\n","        print('Experiment {:d} | Iteration {:d} | {}: {} '.format(j, i, tag, x))\n","\n","color = 'r'\n","X = np.array(X)\n","mean_plot = X.mean(axis=0)\n","std_plot = X.std(axis=0)\n","iters = np.arange(len(mean_plot))\n","plt.plot(iters,mean_plot,color, label=tag)\n","plt.fill_between(iters, mean_plot-std_plot, mean_plot+std_plot, color=color, alpha=0.2)\n","plt.ylabel('reward')\n","plt.xlabel('iteration')\n","plt.legend()"],"metadata":{"id":"CvOksua3LgQa","executionInfo":{"status":"aborted","timestamp":1708965880771,"user_tz":-60,"elapsed":10,"user":{"displayName":"Ruben Martinez-Cantin","userId":"11446784088370650030"}}},"execution_count":null,"outputs":[]}]}